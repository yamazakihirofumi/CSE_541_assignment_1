{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Train---------\n",
      "Label=  7\n",
      "I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "--------Test---------\n",
      "Label=  7\n",
      "I am a little confused on all of the models of the 88-89 bonnevilles.\n",
      "I have heard of the LE SE LSE SSE SSEI. Could someone tell me the\n",
      "differences are far as features or performance. I am also curious to\n",
      "know what the book value is for prefereably the 89 model. And how much\n",
      "less than book value can you usually get them for. In other words how\n",
      "much are they in demand this time of year. I have heard that the mid-spring\n",
      "early summer is the best time to buy.\n",
      "---------------------\n",
      "Vocabulary size:190594\n",
      "Train Matrix size = torch.Size([11314, 100])\n"
     ]
    }
   ],
   "source": [
    "#Doing data pre-processing in this block\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "#pprint(newsgroups_train)\n",
    "train_texts = newsgroups_train.data\n",
    "train_labels = newsgroups_train.target\n",
    "test_texts = newsgroups_test.data\n",
    "test_labels = newsgroups_test.target\n",
    "print(\"--------Train---------\")\n",
    "print(\"Label= \",train_labels[0])\n",
    "print(train_texts[0])\n",
    "\n",
    "print(\"--------Test---------\")\n",
    "print(\"Label= \",test_labels[0])\n",
    "print(test_texts[0])\n",
    "print(\"---------------------\")\n",
    "\n",
    "#Tokenize the input data \n",
    "def tokenize(text):\n",
    "    return text.lower().split()\n",
    "\n",
    "train_tokens = []\n",
    "for txt in train_texts:\n",
    "    tokens = tokenize(txt)\n",
    "    train_tokens.append(tokens)\n",
    "\n",
    "test_tokens = []\n",
    "for txt in test_texts:\n",
    "    tokens = tokenize(txt)\n",
    "    test_tokens.append(tokens)\n",
    "\n",
    "\n",
    "#Build vocabulary\n",
    "word_to_idx = {}\n",
    "word_to_idx['<PAD>'] = 0 \n",
    "word_to_idx['<UNK>'] = 1 \n",
    "\n",
    "#Add tokenized words to vocabulary \n",
    "current_idx = 2 \n",
    "for tokens in train_tokens: \n",
    "    for word in tokens: \n",
    "        if word not in word_to_idx:\n",
    "            word_to_idx[word] = current_idx\n",
    "            current_idx +=1\n",
    "vocab_size = len(word_to_idx)\n",
    "\n",
    "print(\"Vocabulary size:\"+ str(vocab_size))\n",
    "\n",
    "#Convert tokens to sequences of indices\n",
    "train_sequences = []\n",
    "for tokens in train_tokens:\n",
    "    sequence = []\n",
    "    for word in tokens:\n",
    "        #Get the idx of the word, or the UNK token if it's not in val\n",
    "        sequence.append(word_to_idx.get(word,word_to_idx['<UNK>']))\n",
    "    train_sequences.append(sequence)\n",
    "    \n",
    "#Pad sequences to the same length\n",
    "# I choose this randomly, I wish it can give me better result if I change it more. \n",
    "max_length = 100 \n",
    "\n",
    "train_padded = []\n",
    "for sequence in train_sequences:\n",
    "    #Truncate the sequence if it's longer than max_length\n",
    "    if len(sequence) > max_length:\n",
    "        padded_sequence = sequence[:max_length]\n",
    "    else:\n",
    "        padded_sequence = sequence + [word_to_idx['<PAD>']] * (max_length - len(sequence))\n",
    "    train_padded.append(padded_sequence)\n",
    "\n",
    "train_sequences_tensor = torch.LongTensor(train_padded)\n",
    "train_labels_tensor = torch.LongTensor(train_labels)\n",
    "print(\"Train Matrix size = \" + str(train_sequences_tensor.shape) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do embedding after Tokenize them\n",
    "#For the embedding I choose to use w2v because it's simple to use\n",
    "import gensim.downloader as api\n",
    "\n",
    "#Load the word vectors\n",
    "word_vectors = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "embedding_dim = 300\n",
    "embedding_matrix = np.zeros((len(word_to_idx), embedding_dim))\n",
    "\n",
    "for word, idx in word_to_idx.items():\n",
    "    if word in word_vectors:\n",
    "        embedding_matrix[idx] = word_vectors[word]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "#Build RNN\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "class MyRNN(nn.Module):\n",
    "    def __init__(self,vocab_size, embedding_dim, hidden_dim, output_dim,num_layers,embedding_matrix=None):\n",
    "        super(MyRNN, self).__init__()\n",
    "        #Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        #Add a Rnn layer\n",
    "        self.rnn = nn.RNN(embedding_dim,\n",
    "                          hidden_dim,\n",
    "                          num_layers=num_layers,\n",
    "                          batch_first=True)\n",
    "        #Add a fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "    def forward(self,text):\n",
    "        #Run throught the embedding layer\n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        \n",
    "        # Initialize hidden state\n",
    "        batch_size = text.size(0)\n",
    "        \n",
    "        #Run through RNN\n",
    "        output,  hidden = self.rnn(embedded)\n",
    "        # Use the hidden state from the last layer for classification\n",
    "        # Take the last layer's hidden state\n",
    "        last_hidden = hidden[-1]\n",
    "        # Pass through fully connected layer\n",
    "        return self.fc(last_hidden)\n",
    "        \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 3.0009\n",
      "Epoch 2 Loss: 2.8977\n",
      "Epoch 3 Loss: 2.8209\n",
      "Epoch 4 Loss: 2.6690\n",
      "Epoch 5 Loss: 2.3997\n",
      "Epoch 6 Loss: 2.1362\n",
      "Epoch 7 Loss: 1.9303\n",
      "Epoch 8 Loss: 1.8015\n",
      "Epoch 9 Loss: 1.7331\n",
      "Epoch 10 Loss: 1.6910\n"
     ]
    }
   ],
   "source": [
    "# Create dataset and dataloader\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(train_sequences_tensor, train_labels_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "#Define model shapes\n",
    "vocab_size = len(word_to_idx)\n",
    "hidden_dim = 128  # Size of the RNN hidden state\n",
    "output_dim = len(newsgroups_train.target_names)  # Number of classes (20 for 20 Newsgroups)\n",
    "num_layers = 2 \n",
    "batch_size = 64  # Define Batch Size here\n",
    "epochs = 10 \n",
    "\n",
    "#\n",
    "# Initialize the model\n",
    "model = MyRNN(vocab_size, embedding_dim, hidden_dim, output_dim, num_layers,embedding_matrix)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "\n",
    "#Train the rnn\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0 \n",
    "    for texts,labels in train_loader: \n",
    "        #Move to GPU\n",
    "        texts = texts.to(device)\n",
    "        labels = labels.to(device)\n",
    "        #Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #Forward pass \n",
    "        predictions = model(texts)\n",
    "        \n",
    "        #Calculate loss\n",
    "        loss = criterion(predictions, labels)\n",
    "                \n",
    "        #Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        #Update parameters\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f\"Epoch {epoch+1} Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy= [7.5278810408921935]%\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "#Prepair test data\n",
    "\n",
    "test_sequences = []\n",
    "for tokens in test_tokens:\n",
    "    sequence = []\n",
    "    for word in tokens:\n",
    "        sequence.append(word_to_idx.get(word, word_to_idx['<UNK>']))\n",
    "    test_sequences.append(sequence)\n",
    "\n",
    "#Pad sequences\n",
    "test_padded = []\n",
    "for sequence in test_sequences: \n",
    "    if len(sequence) > max_length: \n",
    "        padded_sequence = sequence[:max_length]\n",
    "    else:\n",
    "        padded_sequence = sequence+[word_to_idx['<PAD>']] * (max_length - len(sequence))\n",
    "    test_padded.append(padded_sequence)\n",
    "\n",
    "\n",
    "#Convert to tensors\n",
    "test_sequences_tensor = torch.LongTensor(test_padded)\n",
    "test_labels_tensor = torch.LongTensor(test_labels)\n",
    "\n",
    "#Create test dataset and dataloader\n",
    "test_dataset = TensorDataset(test_sequences_tensor, test_labels_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "correct =0 \n",
    "total = 0\n",
    "    \n",
    "with torch.no_grad():\n",
    "    for texts, labels in test_loader:\n",
    "        #move test to GPU\n",
    "        texts = texts.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #Forward pass\n",
    "        outputs = model(texts)\n",
    "        \n",
    "        #get prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        #Count correct predictions\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "#Calculate and print accuracy\n",
    "accuracy = 100* correct/total\n",
    "print(\"Test accuracy= [\"+str(accuracy)+ \"]%\")\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exported to newsgroups_rnn_model.pt\n"
     ]
    }
   ],
   "source": [
    "#export the model\n",
    "model.eval()\n",
    "dummy_input = torch.zeros((1, max_length), dtype=torch.long).to(device)\n",
    "output_path = \"newsgroups_rnn_model.pt\"\n",
    "\n",
    "# Export to TorchScript\n",
    "scripted_model = torch.jit.trace(model, dummy_input)\n",
    "torch.jit.save(scripted_model, output_path)\n",
    "print(f\"Model exported to {output_path}\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
